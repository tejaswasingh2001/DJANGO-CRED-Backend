{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP6C3RrQjzD4+jYF+0Fqx1U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kPeNjhMaaL4x","executionInfo":{"status":"ok","timestamp":1704740060759,"user_tz":-330,"elapsed":13201,"user":{"displayName":"Tejaswa Singh","userId":"15654547018793683125"}},"outputId":"330c726e-8ff2-431a-a575-c883a1abf8bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting selenium\n","  Downloading selenium-4.16.0-py3-none-any.whl (10.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n","Collecting trio~=0.17 (from selenium)\n","  Downloading trio-0.23.2-py3-none-any.whl (461 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m461.6/461.6 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n","  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n","Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2023.11.17)\n","Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.6)\n","Collecting outcome (from trio~=0.17->selenium)\n","  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n","Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.0)\n","Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n","  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n","Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n","Successfully installed h11-0.14.0 outcome-1.3.0.post0 selenium-4.16.0 trio-0.23.2 trio-websocket-0.11.1 wsproto-1.2.0\n","Collecting pymongo\n","  Downloading pymongo-4.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.1/677.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n","  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: dnspython, pymongo\n","Successfully installed dnspython-2.4.2 pymongo-4.6.1\n"]}],"source":["!pip install selenium\n","!pip install pymongo"]},{"cell_type":"code","source":["#web driver will not work in collab, please run this script locally\n","\n","from selenium import webdriver\n","from selenium.webdriver.common.by import By\n","from selenium.common.exceptions import NoSuchElementException\n","from pymongo import MongoClient\n","import time\n","import re\n","\n","def get_database():\n","\n","   # Provide the mongodb atlas url to connect python to mongodb using pymongo\n","   CONNECTION_STRING = \"mongodb+srv://tejaswa:EJ89ifv6DZ99Lrcy@cluster0.iltzscn.mongodb.net/?retryWrites=true&w=majority\"\n","\n","   # Create a connection using MongoClient. You can import MongoClient or use pymongo.MongoClient\n","   client = MongoClient(CONNECTION_STRING)\n","\n","   # Create the database for our example (we will use the same database throughout the tutorial\n","   return client['indeed_jobs']\n","\n","dbname = get_database()\n","\n","def get_collection():\n","    return dbname[\"indeed_jobs\"]\n","\n","def convert_salary(salary):\n","    matches = re.findall(r'\\$([\\d,]+)(?:\\s*-\\s*\\$([\\d,]+))?\\s*(a\\s*(year|month|hour))?', salary)\n","    salary_mean=0\n","    if matches:\n","        # Extract lower and upper bounds\n","        lower_bound = float(matches[0][0].replace(',', ''))\n","        upper_bound = float(matches[0][1].replace(',', '')) if matches[0][1] else lower_bound\n","\n","        # Check if frequency is specified and adjust mean calculation accordingly\n","        frequency = matches[0][3]\n","        if frequency == 'month':\n","            # If salary is per month, multiply by 12 to get annual salary\n","            lower_bound *= 12\n","            upper_bound *= 12\n","        elif frequency == 'hour':\n","            # If salary is per hour, multiply by average work hours per week and weeks per year\n","            lower_bound *= 40 * 52  # Assuming 40 hours per week and 52 weeks per year\n","            upper_bound *= 40 * 52\n","\n","        # Calculate mean\n","        salary_mean = (lower_bound + upper_bound) / 2\n","\n","    return salary_mean\n","\n","def scrape_jobs():\n","    driver = webdriver.Chrome()\n","\n","    driver.get(f'https://www.indeed.com/jobs?q=Python+Developer')\n","    next_page = 2\n","    jobs = []\n","\n","    while next_page < 9:\n","        time.sleep(10)\n","        job_listings_container = driver.find_element(By.ID, 'mosaic-provider-jobcards')\n","        job_listings_ul = job_listings_container.find_element(By.TAG_NAME, 'ul')\n","        job_listings = job_listings_ul.find_elements(By.XPATH, \"./child::*\")\n","        for job in job_listings:\n","            elemid = job.find_elements(By.XPATH, \"./child::*\")[0].get_attribute('id')\n","            curr_job = job.find_elements(By.XPATH, \"./child::*\")[0]\n","            if elemid == '':\n","                job_title = curr_job.find_element(By.CSS_SELECTOR, 'h2.jobTitle').text\n","                job_company = curr_job.find_element(By.XPATH, \".//span[@data-testid='company-name']\").text\n","                job_location = curr_job.find_element(By.XPATH, \".//div[@data-testid='text-location']\").text\n","                job_salary = 0\n","                try:\n","                    job_salary = convert_salary(curr_job.find_element(By.CSS_SELECTOR, \"div.salary-snippet-container\").text)\n","                except NoSuchElementException:\n","                    job_salary = 0\n","                # job_description = job.find_element(By.CSS_SELECTOR, 'div.summary').text\n","\n","                jobs.append({\n","                    'job_title': job_title,\n","                    'job_company': job_company,\n","                    'job_location': job_location,\n","                    'job_salary': job_salary,\n","                    # 'job_description': job_description\n","                })\n","        # next page\n","        try:\n","            next_page_btn = driver.find_element(By.XPATH, f\"//a[@data-testid='pagination-page-{next_page}']\")\n","            next_page+=1\n","            next_page_btn.click()\n","        except NoSuchElementException:\n","            break\n","\n","    # driver.quit()\n","    return jobs\n","\n","def run():\n","    print(\"Scrapping jobs...\")\n","    scraped_jobs = scrape_jobs()\n","    print(\"Jobs scrapped!\");\n","\n","    #mongodb collection\n","    collection = get_collection()\n","\n","    print(\"Adding data to database...\")\n","\n","    collection.insert_many(scraped_jobs)\n","\n","    print(\"Added jobs to the database!\")"],"metadata":{"id":"IZXo4Y3Ca_VD","executionInfo":{"status":"ok","timestamp":1704740148011,"user_tz":-330,"elapsed":4,"user":{"displayName":"Tejaswa Singh","userId":"15654547018793683125"}}},"execution_count":5,"outputs":[]}]}